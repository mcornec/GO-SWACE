{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8081a4d-a43b-444f-8928-8e6692b1611a",
   "metadata": {},
   "source": [
    "# Plot all SWOT from eddy of interest\n",
    "\n",
    "Authors: SEL, LJK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fed9aec3-1807-4c1f-9444-31bee8636e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import earthaccess\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from scipy.ndimage import generic_filter\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.interpolate import griddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "696b720d-4c11-4d7d-844f-09c5da5a3fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set default fontsizes for plots\n",
    "fontsize = 18\n",
    "\n",
    "plt.rc('font', size=fontsize)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=fontsize)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=fontsize)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=fontsize)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=fontsize)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=fontsize)    # legend fontsize\n",
    "plt.rc('figure', titlesize=fontsize)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e205037b-71a8-4f76-ada6-10cc0960ed8f",
   "metadata": {},
   "source": [
    "### Open AVISO eddy dataset for Edward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763633d9-90a6-4a3a-9282-3b525e98e5e7",
   "metadata": {},
   "source": [
    "### TO DO: Replace this file with Eddy trajectory from your eddy of interest. Also switch out specialid to match filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bbfb544-494c-47f4-b3bc-70c6fb4feb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aviso_ds = xr.open_dataset('Eddy_trajectory_nrt_3.2exp_cyclonic_20180101_20241111_ID_171334.nc')\n",
    "aviso_ds\n",
    "specialid='eddy_ID171334'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c03c442c-0a0c-44fe-9746-8a673276b2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-06T00:00:00.000000000\n",
      "2024-07-20T00:00:00.000000000\n"
     ]
    }
   ],
   "source": [
    "dates = [i for i in aviso_ds.time.values] # these are sorted already\n",
    "print(min(dates))\n",
    "print(max(dates)) # still existed at the end of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa3dc38a-1661-419e-a70d-1381613cd58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tminny=str(min(dates))\n",
    "tminny=tminny[0:10]\n",
    "tmaxxy=str(max(dates))\n",
    "tmaxxy=tmaxxy[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "864d9fc5-0ee4-4243-a6f1-530184484e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin,tmax = tminny,tmaxxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b1fc11c-323a-427c-b87b-da2674427520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258\n"
     ]
    }
   ],
   "source": [
    "center_lats = [i for i in aviso_ds.latitude.values]\n",
    "center_lons = [i for i in aviso_ds.longitude.values]\n",
    "print(len(center_lats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da637da1-54b5-4893-a731-3d733a49f9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.536037\n",
      "33.408527\n",
      "-54.99517822265625\n",
      "-47.05389404296875\n"
     ]
    }
   ],
   "source": [
    "print(min(center_lats))\n",
    "print(max(center_lats))\n",
    "print(min(center_lons)-360)\n",
    "print(max(center_lons)-360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b4076cf-4deb-4362-af3d-58cfe349530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define box based on eddy\n",
    "latmin,latmax = min(center_lats)-2,max(center_lats)+2\n",
    "lonmin,lonmax = min(center_lons)-360-2,max(center_lons)-360+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1f2c5b6-7916-4bdb-a895-7c383767b54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eddy_by_ID_date(ds,eddy_date):\n",
    "    \"\"\"\n",
    "    ds: netCDF AVISO format\n",
    "    track_id: id of eddy to extract\n",
    "    eddy_date: date in format 'YYYY-MM-DD'\n",
    "\n",
    "    Returns contour lons, contour lats, center lon, center lat\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ind = np.where(ds.time == np.datetime64(eddy_date))[0][0]\n",
    "        contour_lons = np.array(ds.effective_contour_longitude[ind])\n",
    "        contour_lats = np.array(ds.effective_contour_latitude[ind])\n",
    "    except:\n",
    "        print('No eddy data available with that request ... :(')        \n",
    "    \n",
    "    return contour_lons,contour_lats,ds.longitude[ind],ds.latitude[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9aacde-da42-4b76-8f52-a9106a84037a",
   "metadata": {},
   "source": [
    "## Eddy timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "244c32cf-dc3f-455c-9767-b1a171a9be93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "# p0 = ax.plot(aviso_ds.amplitude,c='k')\n",
    "# ax.set_ylabel('Amplitude (m)')\n",
    "\n",
    "# axa_color = 'C0'\n",
    "# axa = ax.twinx()\n",
    "# p1 = axa.plot(aviso_ds.effective_area,c=axa_color)\n",
    "# axa.set_ylabel('Area (m$^2$)',rotation=270,labelpad=25)\n",
    "\n",
    "# axa.yaxis.label.set_color(axa_color)          #setting up Y-axis label color to blue\n",
    "# axa.tick_params(axis='y', colors=axa_color)  #setting up Y-axis tick color to black\n",
    "# axa.spines['right'].set_color(axa_color)        # setting up Y-axis tick color to red\n",
    "\n",
    "# ax.set_xlabel('Days Since Genesis')\n",
    "\n",
    "# ax.axvline(0,0,1,linestyle = '--', c='g', label=str(min(dates))[0:10])\n",
    "# ax.axvline(len(aviso_ds.effective_area)-1,0,1,linestyle = '--', c='r', label=str(max(dates))[0:10])\n",
    "\n",
    "# ax.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8680f4f6-a716-4cb1-bffa-8d4321876e3c",
   "metadata": {},
   "source": [
    "### Find the SWOT days with 2 passes over the eddy area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4359c64-cca4-4c5c-ba8d-775aaf01c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = earthaccess.login(persist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a016dc79-a550-45cb-b1ce-bf308cee4e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_swot_data(latmin,latmax,lonmin,lonmax,tmin,tmax):\n",
    "    \"\"\"\n",
    "    Searches for SWOT data within the bounding box and time. Note that this doesn't work for unsmoothed data. \n",
    "    \n",
    "    latmin,latmax: latitude bounds, degrees N (south is negative); floats\n",
    "    lonmin, lonmax: longitude bounds, degrees E (west is negative); floats\n",
    "    tmin,tmax: temporal bounds; strings of form 'yyyy-mm-dd'\n",
    "    \"\"\"\n",
    "    bbox = (lonmin, latmin, lonmax, latmax) # lonW, latS, lonE, latN\n",
    "    results = earthaccess.search_data(\n",
    "        short_name=\"SWOT_L2_LR_SSH_EXPERT_2.0\",\n",
    "        bounding_box=bbox,\n",
    "        temporal=(tmin,tmax))\n",
    "    \n",
    "    print(\"Number of swaths: \" + str(len(results))) # not daily files, so will likely be more than # of days\n",
    "    paths = earthaccess.open(results) # is there a way to choose a subset of variables here?\n",
    "\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f32c4e79-262e-4f38-b8f9-f5a20c2c9547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of swaths: 364\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497f870b66834e3c8f4db1a168c7f951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e022190bf26548459c95afddec05e81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb474f14b01b4d569d21e5ab6e2d57b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edward_paths = get_swot_data(latmin,latmax,lonmin,lonmax,tmin,tmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0899098-cf55-4cfe-8222-d4054a9e56e2",
   "metadata": {},
   "source": [
    "Get unique dates that have a swath in the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0427308d-a407-4361-ac42-6e515f6a9b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20231106', '20231107', '20231108', '20231112', '20231113', '20231114', '20231115', '20231116', '20231117', '20231118', '20231123', '20231124', '20231125', '20231126', '20231127', '20231128', '20231129', '20231203', '20231204', '20231205', '20231206', '20231207', '20231208', '20231214', '20231215', '20231216', '20231217', '20231218', '20231219', '20231228', '20231229', '20240104', '20240105', '20240106', '20240107', '20240108', '20240109', '20240114', '20240115', '20240116', '20240117', '20240118', '20240119', '20240125', '20240126', '20240127', '20240128', '20240129', '20240130', '20240204', '20240205', '20240206', '20240207', '20240208', '20240209', '20240215', '20240216', '20240217', '20240218', '20240219', '20240220', '20240224', '20240225', '20240226', '20240227', '20240228', '20240229', '20240301', '20240306', '20240307', '20240308', '20240309', '20240310', '20240311', '20240312', '20240316', '20240317', '20240318', '20240319', '20240320', '20240321', '20240322', '20240327', '20240328', '20240329', '20240330', '20240331', '20240401', '20240402', '20240406', '20240407', '20240408', '20240409', '20240410', '20240411', '20240412', '20240417', '20240418', '20240419', '20240420', '20240421', '20240422', '20240423', '20240427', '20240428', '20240429', '20240430', '20240501', '20240502', '20240503', '20240508', '20240509', '20240510', '20240513', '20240518', '20240519', '20240520', '20240521', '20240522', '20240523', '20240529', '20240530', '20240531', '20240601', '20240602', '20240603', '20240608', '20240609', '20240610', '20240611', '20240612', '20240613', '20240619', '20240620', '20240621', '20240622', '20240623', '20240624', '20240629', '20240630', '20240701', '20240702', '20240703', '20240704', '20240710', '20240711', '20240712', '20240713', '20240714', '20240715', '20240720']\n"
     ]
    }
   ],
   "source": [
    "dates_available = []\n",
    "for i in edward_paths:\n",
    "    today = str(i).split('-')[-1].split('_')[-4][0:8]\n",
    "    if today not in dates_available:\n",
    "        dates_available.append(today)\n",
    "print(dates_available)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41952b31-1288-4fa1-8fc6-8adacd1e9033",
   "metadata": {},
   "source": [
    "Version control to get the QC path for each swath\n",
    "\n",
    "Note: not all swaths have a v2, and PGC0 is preferred over PIC0; documentation here: https://www.aviso.altimetry.fr/en/data/products/sea-surface-height-products/global/swot-karin-low-rate-ocean-products.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e56655f7-eac0-4bb1-bee1-05641ccab62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "272\n"
     ]
    }
   ],
   "source": [
    "edward_PGC0_paths,edward_PIC0_paths = [],[]\n",
    "\n",
    "for p in edward_paths:\n",
    "    if str(p).split('_')[-2] == 'PGC0':\n",
    "        edward_PGC0_paths.append(p)\n",
    "    else:\n",
    "        edward_PIC0_paths.append(p)\n",
    "\n",
    "print(len(edward_PGC0_paths))\n",
    "print(len(edward_PIC0_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdcba1e-826b-48d7-871b-d5140ff562ee",
   "metadata": {},
   "source": [
    "Remove v1 if there's a v2, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2aad7aa-93d4-4a94-bd9c-e55fff737648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unneeded_versions(path_list):\n",
    "    non_v1_paths = [i for i in path_list if int(str(i).split('_')[-1][0:2]) > 1]    \n",
    "    for p in non_v1_paths:\n",
    "        version = int(str(p).split('_')[-1][0:2])\n",
    "        for v in np.arange(1,version): # remove all versions  less than the highest\n",
    "            if str(p)[:-5] + str(v) + '.nc>' in path_list: # check if that earlier version is in list\n",
    "                path_list.remove(str(p)[:-5] + str(v) + '.nc>')\n",
    "    return path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67c0a89d-81bf-4e84-ae2c-5f4198d090ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "272\n"
     ]
    }
   ],
   "source": [
    "# these lists will have one of each timestep\n",
    "edward_PGC0_paths_filtered = remove_unneeded_versions(edward_PGC0_paths)\n",
    "edward_PIC0_paths_filtered = remove_unneeded_versions(edward_PIC0_paths)\n",
    "\n",
    "print(len(edward_PGC0_paths_filtered))\n",
    "print(len(edward_PIC0_paths_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65a6a54-d8f1-4415-9879-526813fdee28",
   "metadata": {},
   "source": [
    "Now check if any of the PGC0 timestamps are in PIC0, then remove PIC0 filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5fc2b72-f708-4332-adff-9064180d1705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272\n"
     ]
    }
   ],
   "source": [
    "edward_paths_filtered = []\n",
    "\n",
    "for i in edward_PIC0_paths_filtered:\n",
    "    match = 0\n",
    "    for p in edward_PGC0_paths_filtered:\n",
    "        if str(i).split('-')[-1].split('_')[-4] == str(p).split('-')[-1].split('_')[-4]: # same timestamp\n",
    "            edward_paths_filtered.append(p)\n",
    "            match = 1\n",
    "            break\n",
    "    if match == 0: # no match\n",
    "        edward_paths_filtered.append(i)\n",
    "\n",
    "print(len(edward_paths_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60021ca4-a25d-4711-aa85-a17242d9b4c6",
   "metadata": {},
   "source": [
    "Paths are finally filtered, so we can look for true double pass dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea841b29-559b-4ea9-91c6-fd18476c1514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272\n",
      "122\n"
     ]
    }
   ],
   "source": [
    "dates_available,double_passes = [],[]\n",
    "dates_available_version_control = {}\n",
    "\n",
    "ind = 0\n",
    "for i in edward_paths_filtered:\n",
    "    today = str(i).split('-')[-1].split('_')[-4][0:8]\n",
    "    dates_available.append(today)\n",
    "    if today not in dates_available_version_control:\n",
    "        dates_available_version_control[today] = ind\n",
    "    elif today not in double_passes:\n",
    "        double_passes.append(today)\n",
    "    ind += 1\n",
    "    \n",
    "print(len(dates_available))\n",
    "print(len(double_passes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5834ad0-87b0-4ce0-9fd9-8b6e60aa55e3",
   "metadata": {},
   "source": [
    "## Plot eddy & SWOT data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ca4431-23df-4623-9470-4df594892221",
   "metadata": {},
   "source": [
    "Using calculations from “SWOT_velocities_over_PACE.ipynb”. Shouldn't need to regrid like this with L3 SWOT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0126b3df-43ed-4e05-a0b3-cc43323b46aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_inds_for_requested_date(paths,date_requested):\n",
    "    inds = []\n",
    "    ind = 0 \n",
    "    for i in paths:\n",
    "        today = str(i).split('-')[-1].split('_')[-4][0:8]\n",
    "        if date_requested == today:\n",
    "            inds.append(ind)\n",
    "        ind += 1\n",
    "\n",
    "    return inds    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72b896d7-5133-42be-8f81-e9a0ad9e854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_dataset_by_lat_lon(ds,latmin,latmax,lonmin,lonmax):\n",
    "    mask = (ds.latitude >= latmin) & (ds.latitude <= latmax) & (ds.longitude >= lonmin+360) & (ds.longitude <= lonmax+360)\n",
    "    ds_masked = ds.where(mask, drop=True)\n",
    "    return ds_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c26b8fbb-543d-4e47-819a-f4f13748efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_dataset_regrid(ds,latmin,latmax,lonmin,lonmax):\n",
    "\n",
    "    # Crop dataset based on requested bounds\n",
    "    mask = (ds.latitude >= latmin) & (ds.latitude <= latmax) & (ds.longitude >= lonmin+360) & (ds.longitude <= lonmax+360)\n",
    "    ds_masked = ds.where(mask, drop=True)\n",
    "\n",
    "    # Set up grid to project data onto\n",
    "    res = 0.036\n",
    "    if lonmin < 0:\n",
    "        lonmin = lonmin+360\n",
    "    if lonmax < 0:\n",
    "        lonmax = lonmax+360\n",
    "    \n",
    "    xv = np.arange(lonmin,lonmax,res)\n",
    "    yv = np.arange(latmin,latmax,res)\n",
    "    grid_x, grid_y = np.meshgrid(xv,yv)\n",
    "\n",
    "    # Grid the SLA data\n",
    "    sla=ds_masked.ssha_karin_2+ds_masked.height_cor_xover\n",
    "    lat=ds_masked.latitude\n",
    "    lon=ds_masked.longitude\n",
    "    grid_sla = griddata((lon.values.ravel(),lat.values.ravel()), sla.values.ravel(), (grid_x, grid_y), method='linear')\n",
    "    \n",
    "    return grid_sla,grid_x,grid_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c60459-833e-4d04-9051-087fa56208db",
   "metadata": {},
   "source": [
    "Copying these SWOT vel calculations from \"SWOT_velocities_over_PACE.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a5babf5-0ee7-43df-8bad-ba77e7dc9faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_geos_current(grid_sla,grid_lat):\n",
    "    \"\"\"\n",
    "    grid_sla: (m) Make sure this is first corrected with height_cor_xover from L2 data! \n",
    "    grid_lat: degrees N\n",
    "    \"\"\"\n",
    "    \n",
    "    omega = 7.2921159e-05  # angular velocity of the Earth [rad/s]\n",
    "    fc = 2*omega*np.sin(grid_lat*np.pi/180.)\n",
    "        \n",
    "    # avoid zero near equator, bound fc by min val as 1.e-8\n",
    "    f_coriolis = np.sign(fc)*np.maximum(np.abs(fc), 1.e-8)\n",
    "    \n",
    "    dx,dy = 4000,4000 # m i changed it to 4000 to match res? need to double check\n",
    "    gravity = 9.81\n",
    "\n",
    "    dsdy,dsdx=np.array(np.gradient(grid_sla, dx, edge_order=1))\n",
    "    vg = (gravity/np.array(f_coriolis))*dsdx\n",
    "    ug = -(gravity/np.array(f_coriolis))*dsdy\n",
    "    geos_current = np.sqrt(ug**2 + vg**2)\n",
    "    \n",
    "    return ug,vg,geos_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "968b7b6b-15e5-4531-b38d-0ed1fd42ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_swaths_on_date(ax,date_requested,gridded=0):\n",
    "    \"\"\"\n",
    "    date_requested: 'YYYYMMDD'\n",
    "    gridded: 0 or 1 (aka no or yes)\n",
    "    \"\"\"\n",
    "    \n",
    "    inds = get_path_inds_for_requested_date(edward_paths_filtered,date_requested)\n",
    "    for i in inds:\n",
    "        swot_ds = xr.open_dataset(edward_paths_filtered[i])\n",
    "\n",
    "        if gridded == 0:\n",
    "            swot_ds_masked = crop_dataset_by_lat_lon(swot_ds,latmin,latmax+1,lonmin,lonmax+1)\n",
    "            plot = ax.pcolormesh(swot_ds_masked.longitude-360,swot_ds_masked.latitude,swot_ds_masked.ssha_karin_2+swot_ds_masked.height_cor_xover,cmap='coolwarm',vmin=-1,vmax=1)\n",
    "        elif gridded == 1:\n",
    "            # Regrid the data uniformly\n",
    "            grid_sla,grid_x,grid_y = crop_dataset_regrid(swot_ds,latmin,latmax+2,lonmin,lonmax+2)\n",
    "            plot = ax.pcolormesh(grid_x-360,grid_y,grid_sla,cmap='coolwarm',vmin=-1,vmax=1)\n",
    "\n",
    "            # Add in geotrophic velocity streamplot\n",
    "            ug,vg,geos_current = compute_geos_current(grid_sla,grid_y)\n",
    "            ax.streamplot(grid_x-360,grid_y,ug,vg, density = 3, color = 'k',linewidth=1)\n",
    "    \n",
    "    # plot AVISO eddy contour\n",
    "    contour_lons,contour_lats,center_lon,center_lat = get_eddy_by_ID_date(aviso_ds,'%s-%s-%s'%(date_requested[0:4],date_requested[4:6],date_requested[6:8]))\n",
    "    ax.plot(contour_lons-360,contour_lats,zorder=100,c='k',linewidth=2)\n",
    "\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a449d39-bf88-41f8-9104-a443e9f86bd8",
   "metadata": {},
   "source": [
    "NOTE: The double pass dates do not necessarily intersect the eddy, they were included if there was two passes in the box\n",
    "\n",
    "Dates checked that don't cross eddy:\n",
    "- '20231214',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63538e15-938b-4736-bd36-6829f9bf025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for IDX in range(0,len(double_passes)):\n",
    "    date=double_passes[IDX]\n",
    "    try:\n",
    "        fig,ax=plt.subplots(figsize=(8,5))\n",
    "        plot = plot_all_swaths_on_date(ax,date,1)\n",
    "        cbar = plt.colorbar(plot,ax=ax)\n",
    "        cbar.set_label('SLA (m)',rotation=270, labelpad=15)\n",
    "        ax.set_ylabel('Latitude (N$^{\\circ}$)')\n",
    "        ax.set_xlabel('Longitude (E$^{\\circ}$)')\n",
    "        ax.set_title(str(date))\n",
    "        plt.savefig(str(specialid) + '_swot_%s.png'%(date),dpi=300)\n",
    "        plt.close()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837aeba4-9b7e-4b0a-b165-a31f19efd7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "# Get a list of all PNG files in the directory\n",
    "image_dir = '/home/jovyan/GO-SWACE/'\n",
    "images = [img for img in os.listdir(image_dir) if img.endswith(\".png\")]\n",
    "images.sort()  # Sort the images if needed\n",
    "# Create a figure and axis for the animation\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Function to update the figure for each frame\n",
    "def update(frame):\n",
    "    img_path = os.path.join(image_dir, images[frame])\n",
    "    img = plt.imread(img_path)\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')  # Hide axes\n",
    "# Create the animation\n",
    "ani = animation.FuncAnimation(fig, update, frames=len(images), repeat=True)\n",
    "\n",
    "# Save the animation as a GIF or display it\n",
    "# ani.save('animation_edward_all.gif', writer='imagemagick', fps=3)  # Save as GIF #was fps=2\n",
    "ani.save('animation_swot_' str(specialid) + '.gif', writer='imagemagick', fps=3)  # Save as GIF #was fps=2\n",
    "\n",
    "# plt.show()  # Uncomment to display the animation\n",
    " \n",
    "print(\"Animation created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7c0891-2f04-4046-bcd6-af0e2b7abc8b",
   "metadata": {},
   "source": [
    "### Eddy Transit Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75df690a-24c0-4901-bfbb-77cf24015258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(12, 12))\n",
    "# gs = fig.add_gridspec(nrows=3, ncols=3)\n",
    "# ax0 = fig.add_subplot(gs[:-1, :],projection=ccrs.PlateCarree())\n",
    "# ax1 = fig.add_subplot(gs[-1, 0])\n",
    "# ax2 = fig.add_subplot(gs[-1, 1])\n",
    "# ax3 = fig.add_subplot(gs[-1, 2])\n",
    "\n",
    "# plt.subplots_adjust(hspace=0.4)\n",
    "\n",
    "# #################### SWOT SUBPLOTS ####################\n",
    "\n",
    "# dates_to_plot = ['20240103','20240406','20240710']\n",
    "# #dates_to_plot = ['20240710','20240406','20240103'] # reverse the order \n",
    "\n",
    "# plot = plot_all_swaths_on_date(ax1,dates_to_plot[0],1)\n",
    "# plot = plot_all_swaths_on_date(ax2,dates_to_plot[1],1)\n",
    "# plot = plot_all_swaths_on_date(ax3,dates_to_plot[2],1)\n",
    "\n",
    "# ind1 = np.where([d==np.datetime64('%s-%s-%s'%(dates_to_plot[0][0:4],dates_to_plot[0][4:6],dates_to_plot[0][6:8])) for d in dates])[0][0]\n",
    "# ind2 = np.where([d==np.datetime64('%s-%s-%s'%(dates_to_plot[1][0:4],dates_to_plot[1][4:6],dates_to_plot[1][6:8])) for d in dates])[0][0]\n",
    "# ind3 = np.where([d==np.datetime64('%s-%s-%s'%(dates_to_plot[2][0:4],dates_to_plot[2][4:6],dates_to_plot[2][6:8])) for d in dates])[0][0]\n",
    "\n",
    "# ax1.set_title('%s-%s-%s'%(dates_to_plot[0][0:4],dates_to_plot[0][4:6],dates_to_plot[0][6:8]))\n",
    "# ax2.set_title('%s-%s-%s'%(dates_to_plot[1][0:4],dates_to_plot[1][4:6],dates_to_plot[1][6:8]))\n",
    "# ax3.set_title('%s-%s-%s'%(dates_to_plot[2][0:4],dates_to_plot[2][4:6],dates_to_plot[2][6:8]))\n",
    "\n",
    "# #cax = ax3.add_axes([0.2, 0.0, 0.05, 0.8]) # x0, y0, width, height\n",
    "# #cbar = plt.colorbar(plot,ax=cax)\n",
    "# #cbar.set_label('SLA (m)',rotation=270, labelpad=15)\n",
    "\n",
    "# ax1.set_ylabel('Latitude (N$^{\\circ}$)')\n",
    "# ax1.set_xlabel('Longitude (E$^{\\circ}$)')\n",
    "\n",
    "# #################### MAP: ax0 ####################\n",
    "\n",
    "# skip = 2\n",
    "# scat = ax0.scatter(center_lons[::skip],center_lats[::skip],s=50,edgecolor='k',c=np.arange(0,len(dates))[::skip],cmap='binary') #small dots of every date\n",
    "\n",
    "# highlight_lons,highlight_lats = [],[]\n",
    "\n",
    "# count = 0\n",
    "# for d in dates_to_plot:\n",
    "#     ind = np.where([i==np.datetime64('%s-%s-%s'%(d[0:4],d[4:6],d[6:8])) for i in dates])[0][0]\n",
    "#     ax0.scatter(center_lons[ind],center_lats[ind],marker='*',c='r',s=500,edgecolor='k')\n",
    "        \n",
    "#     count += 1\n",
    "\n",
    "# xmin,xmax = -75,-65\n",
    "# ymin,ymax = 33,43\n",
    "\n",
    "# ax0.coastlines()\n",
    "# ax0.set_xlim([xmin,xmax])\n",
    "# ax0.set_ylim([ymin,ymax])\n",
    "# ax0.set_xticks(range(xmin,xmax, 5)) \n",
    "# ax0.set_yticks(range(ymin,ymax, 5)) \n",
    "\n",
    "# ax0.set_ylabel('Latitude (N$^{\\circ}$)')\n",
    "# ax0.set_xlabel('Longitude (E$^{\\circ}$)')\n",
    "\n",
    "# # Colorbar\n",
    "# cbar = plt.colorbar(scat, ax=ax0)\n",
    "# cbar.set_label('Day Since Genesis',rotation=270,labelpad=20)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ea6601-db14-43a2-afd8-e0b5d8ff68eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
